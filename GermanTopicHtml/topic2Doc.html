 <!DOCTYPE html>  
    <html lang="de">  
<head>  
    <meta charset="UTF-8">  
    <title>topic</title>  
</head>   <p>Fanfictions wurden mit dem Aufstieg des Internets in den letzten Jahren zu einem wichtigen literarischen Genre der Online-Kultur und vielfach in den Digital Humanities mit unterschiedlichen Methoden untersucht. Der Großteil der Forschung ist jedoch momentan noch auf englisch-sprachige Korpora und Analysen konzentriert. Wir präsentieren Ergebnisse eines <span style="color: rgb(3, 252, 0);">Projekt</span> zur Analyse deutschsprachiger Fanfiction-Korpora mit Fokus auf Fragestellungen von Geschlechterrollen im <span style="color: rgb(4, 251, 0);">Text</span> und von Autor*innen. Wir berichten über die Akquise von über 410.000 deutschsprachigen Fanfictions und Metadaten von den Plattformen Fanfiktion.de und Archive of Our Own. Mittels Metadatenanalysen, NER und computergestützter Geschlechtserkennung von Namen <span style="color: rgb(5, 250, 0);">stellen</span> wir fest, dass der Großteil der Autor*innen weiblich ist aber primär über männliche Figuren, häufig im Kontext homo-romantischer Beziehungen schreibt. Wir diskutieren die Ergebnisse und Limitationen unseres Projekts im Kontext bisheriger Forschung.</p><p>Die Präsentation beschreibt die Entwicklung eines internationales gemeinsames Masterstudiengang in Digital Humanities, der Joint Master in Digital Humanities (JMDH), zwischen den Universitäten Rostock (Deutschland), La Rochelle (Frankreich), Zadar (Kroatien), Klaipeda (Litauen) und Valencia (Spanien). Ziel ist es, die Forschungsschwerpunkte aller Universitäten zu nutzen, um ein breites interdisziplinäres Spektrum an Kursen für Studierende mit Interesse an DH anzubieten. Das Studienprogramm ist so konzipiert, dass es sowohl die Interessen von Studierenden mit geisteswissenschaftlichem Hintergrund als auch von solchen mit Informatik- oder informationswissenschaftlichem Hintergrund bedient. Der Studiengang wird im Rahmen der European University for Smart Urban Coastal Sustainability (EU-CONEXUS) aufgebaut, die sich aus europäischen Institutionen konstituiert.</p><p>In den letzten 2-3 Jahren haben die vielfältigen Weisen, mit denen Bedeutung mittels großer Sprachmodelle hergestellt, untersucht und kommuniziert werden, bisherige Annahmen darüber, wie Forschende in den DH hermeneutische Bedeutung mit KI-basierten Instrumenten untersuchen, in Frage gestellt. Ziel des Panels ist es, die Konstruktion sprachlicher Bedeutung von Menschen und von großen Sprachmodellen durch eine theoretisch informierte und begrifflich differenzierte Beschreibungssprache genauer erfassen zu können, um auf diese Weise die Fortschritte, die Probleme und auch das Scheitern genauer beschreiben zu können. Geleistet wird dies durch (1) eine genauere Rekonstruktion der Bedeutungskonstruktion in großen Sprachmodellen, (2) einen systematischen Theorieimport aus der Sprachphilosophie, (3) durch einen Untersuchung des Zusammenhangs von Bedeutung, Wissen und Modell sowie (4) durch einen Blick auf die Rolle, die bedeutungsanalytische Verfahren in den Digital Humanities spielen.</p><p>Der Thesaurus Linguae Latinae (TLL) ist ein umfassendes einsprachiges Wörterbuch, das kontextualisierte Bedeutungen und Verwendungen lateinischer Wörter in antiken Quellen verzeichnet. Wir haben einen neuen Datensatz zum Wortbedeutungsdisambiguierung (Word Sense Disambiguation) erstellt, der auf Bedeutungsdarstellungen im TLL basiert, und haben damit das Latin-BERT-Modell finegetuned. Unsere BERT-Resultate auf TLL-Daten sind besser als mit einem Vergleichsmodell (biLSTM-Architektur mit static embeddings) erzeugte, und ergaben eine höhere und robustere Leistung. Wir diskutieren die Unterschiede der Prinzipien für die Organisation der Bedeutungenzwischen den beiden lexikalischen Ressourcen und berichten über unsere Datensatzkonstruktion und verbesserte Bewertungsmethode.</p><p>Der hier vorgeschlagene Konferenzbeitrag soll Ergebnisse einer automatisierten Analyse des Datenpakets Parlspeech V2 (cf. Rauh und Schwalbach, 2020a) präsentieren, in der die These einer, im europäischen Vergleich verzögerten Entwicklung des niederländischen literarischen Feldes quantitativ überprüft wird. Die Fragestellung des Teilprojektes lautet: Wie sieht der literarische Referenzrahmen von Politiker*innen aus, der sich mit Hilfe von Rosengrens Mentions Technik rekonstruieren lässt und inwiefern lassen sich literaturhistorisch etablierte Bilder des Verhältnisses von literarischem und politischem Feld an ihm überprüfen? Die manuelle Technik von Rosengren wird zur Beantwortung dieser Frage mit Hilfe digitaler Datenverarbeitungsformen [pythonbasierter Suchalgorithmus, Verarbeitung der Metadaten mit Pandas] transformiert. Die Ergebnisse dieses Workflows basieren auf einer systematischen Suche nach allen Autor*innen des sogenannten nationalen Kanons der Niederlande [De Nederlandstalige Literaire Canon(s)] (cf. Deinsen et al., 2022) im direkten Vergleich zu allen Autor*innen, die in Blooms The Western Canon (cf. Bloom, 1994) genannt werden.</p><p>Normdaten bilden heute einen zentralen Pfeiler der DH; quasi kein <span style="color: rgb(3, 252, 0);">Projekt</span> kommt ohne sie aus. Gerade für die Digital Humanities im deutschsprachigen Raum ist hier die GND die zentrale Anlaufstelle. Zeit deren aktuelle Datenqualität und Kollaborationen mit der Community neu zu beleuchten. Insbesondere soll die seit vielen Jahren bestehende Kooperation der GND mit der deutschsprachigen Wikipedia diskutiert werden. Im Rahmen des Vortrages sollen die GND-Fehlermeldungen der Wikipedia und Möglichkeiten zur Mitarbeit genauer vorgestellt werden und eine detaillierte statistische Auswertung der Meldungen an sich sowie der erfolgten Rückmeldungen der GND-Redaktionen präsentiert werden.</p><p>In den letzten Jahrzehnten haben sich unsere Möglichkeiten zur Visualisierung von Information rasant weiterentwickelt. Für die Untersuchung bestimmter Fragestellungen sind digitale Methoden in Wissenschaft und Forschung längst angekommen. Das gilt auch für die Erforschung frühmittelalterlicher Diagramme. Diese bieten einzigartige Einblicke in die Wissensdarstellung und -vermittlung dieser Epoche. Die Editionspraxis muss daher Methoden und Werkzeuge entwickeln, um ihre Sprache zu entschlüsseln und so eine korrekte Interpretation zu ermöglichen. Für eine thematische Annäherung sollen durch mein <span style="color: rgb(3, 252, 0);">Poster</span> insgesamt drei Wissenschaftsfelder betrachtet werden: 1) Semiologie 2) Editionswissenschaft 3) Sprachwissenschaft. Thematisch stehen <span style="color: rgb(2, 253, 0);">dabei</span> drei Aspekte im Fokus: 1) Entwicklung einer Beschreibungssprache für Diagramme 2) Strategien der Repräsentation im Skalenmodell 3) Dimensionen von Semantik in den Diagrammen. Die wesentlichen Aussagen sollen auf dem <span style="color: rgb(3, 252, 0);">Poster</span> grafisch präsentiert werden.</p><p>This paper investigates trustworthiness in the public debate about the reliability of large-language model-based chatbots, such as ChatGPT by applying a mixed-method approach to German data from the German Digital Dictionary (DWDS). The paper aims to account for how trustworthiness in human-machine interaction can be quantified and how to obtain a domain-independent set of trust-relevant linguistic cues. We use manual annotation in Maxqda to obtain trust-related linguistic markers and identify the level of trustworthiness indicated by them. Afterwards, given that trustworthiness is a complex trust-related phenomenon with cognitive and affective properties, we explore the correlation between the level of trustworthiness with sentiment scores for trust-related markers obtained by human ratings, machine learning and lexicon-based sentiment models. The results indicate a high correlation between positive sentiment scores obtained by sentiment models and trustworthiness obtained by human annotation. In this regard, sentiment analysis also provides evidence for the quantification of emotional aspects of trust.</p><p>Das <span style="color: rgb(3, 252, 0);">Poster</span> präsentiert eine Online-Ressource, die es erlaubt 523 Redeeinleiter dynamisch zu durchsuchen. Sie bietet damit niedrigschwelligen Zugang zu empirischen Daten aus einem umfangreich manuell annotierten Korpus von fiktionalen und nicht-fiktionalen Texten, die zwischen 1850 und 1919 erschienen sind. Durch die Einbindung in eine große Forschungsinf-rastruktur wird Zugänglichkeit garantiert und Nachnutzung vereinfacht.</p> </html>