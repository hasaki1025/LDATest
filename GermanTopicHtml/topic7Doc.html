 <!DOCTYPE html>  
    <html lang="de">  
<head>  
    <meta charset="UTF-8">  
    <title>topic</title>  
</head>   <p>Die Daidalos-Infrastruktur soll es Forschenden der Klassischen Philologie und verwandter Disziplinen ermöglichen, verschiedene Methoden des Natural Language Processing an selbst zusammengestellten Forschungskorpora anzuwenden. Doch wie können potentielle User Forschungsfragen entwickeln und mithilfe von Daidalos untersuchen, wenn sich ihre Forschungskompetenz nicht auf Methoden der Digital Humanities erstreckt? Um dem dadurch zu erwartenden Akzeptanzproblem vorzubeugen, setzt das Daidalos-Projekt auf Forschungstandems. Mithilfe authentischer Use Cases erarbeitet es Bedienworkflows, Funktionalität und kuratierte Lernangebote, die einen niedrigschwelligen Zugang ermöglichen sollen.</p><p>Im April 2022 wurde das Weißbuch "Citizen-Science-Strategie 2030 für Deutschland" mit 15 Handlungsfeldern veröffentlicht. Das Ziel ist es, die Citizen Science in Gesellschaft und Wissenschaft zu stärken, um deren Innovationspotenziale entfalten zu können. Für Digital Humanities bieten die Citizen-Science-Konzepte viel Potenzial, aber bringen auch diverse Herausforderungen mit sich. Eine allgemeine Citizen-Science-Strategie ist ein guter Startpunkt für die Entfaltung ihres Potenzials. Aber es muss auch eine spezifische Citizen-Science-Strategie für Digital-Humanities-Projekte ausgearbeitet beziehungsweise verfolgt werden, um die Potenziale zu entfalten und die Herausforderungen zu meistern. Das wird im Rahmen dieses Vortrages anhand von drei Beispielprojekten – Itinera Nova, Beginen in Köln und DigiByzSeal – und drei Handlungsfeldern aus dem Weißbuch – 1) Freiwilligenmanagement, 2) Datenqualität und Datenmanagement, 3) Sensorik und künstliche Intelligenz –, die für Citizen Science Digital Humanities Projekte insbesondere relevant sind, veranschaulicht.</p><p>"DH Quo Vadis?" Zur Beantwortung dieser Frage scheint es sinnvoll zu betrachten, welchen Anklang die DH in den wissenschaftlichen Disziplinen gefunden haben und welche Maßnahmen aufgrund dieser Betrachtungen getroffen werden sollten. In diesem Vortrag soll dies am Beispiel der Theologie näher beleuchtet werden. Weshalb spielt DH hier nur eine geringe Rolle? Verschiedene Faktoren zur Beantwortung dieser Frage werden genauer untersucht: Zum Teil wird ein Engagement in den DH von Theolog*innen aus verschiedenen Gründen abgelehnt, zum Teil verstehen sie aber auch unter dem Label der DH andere Phänomene oder führen DH-spezifische Praktiken unter einem anderen Label durch. Die Analyse soll dazu beitragen, die Entwicklung und Ausdifferenzierung der Digital Humanities an diesem Beispiel besser nachvollziehen zu können.</p><p>Owing to its late-comer status in Digital Humanities circles, <span style="color: rgb(5, 250, 0);">digital</span> musicology (apart from work in Music Information Retrieval) continues to sort out applicable methodologies for symbiotic relationships with analogue approaches for responding to musicological questions. One systemic area for (re-)consideration in this field is labour visibility. As <span style="color: rgb(5, 250, 0);">digital</span> scholarship increasingly adopts and adheres to the FAIR and CARE principles, invisible labour becomes increasingly unacceptable, especially as <span style="color: rgb(5, 250, 0);">digital</span> ecosystems continually remove limitations of space and finance for acknowledging contributions. This presentation posits FAIR/CARE as ideal normative ethics and offers practical examples for increasing labour visibility within musicological projects, both <span style="color: rgb(5, 250, 0);">digital</span> and analogue.</p><p>Die Edition der Reichstagsakten ist seit 2012 in einer Volltext-Fassung im Internet zugänglich. Sie enthält zeitgenössische Datumsangaben, die üblicherweise auf die Zahl der Tage vor oder nach einen Heiligen- oder Festtag verweisen ("feria quarta post Bartholomei", "montag nach St. Ulrichs tag"). In einigen Bänden sind diese Datierungen durch ein modernes Datum (julianischer Kalender) bereits durch den Bandbearbeiter ergänzt worden. Die Datierungen sind bisher in speziellen Nachschlagewerken, mittlerweile <span style="color: rgb(5, 250, 0);">digital</span> verfügbar und über Umrechnungstabellen (Grotefend [2004]) bestimmbar. Hier wird der Versuch beschrieben, mit Hilfe geeigneter Graphen, die die linguistische Struktur abbilden, und dem Corpus Prozessors Unitex, sowohl Wörterbücher für die fraglichen Enitäten abzuleiten, also auch ein Tagging der zentralen Entitäten (Wochentage, Heiligennamen) zu erzeugen. Anschließend soll probiert werden, die Graphen so zu modifizieren und zu verallgemeinern, dass sie sich auf weitere Textzeugen anwenden lassen.</p><p>In der Fachdiskussion der Philosophie, insbesondere in der historisch informierten Wissenschaftstheorie, finden sich mehr und mehr Arbeiten, die mit Text Mining-Methoden historische Korpora untersuchen. Allerdings stellen die Mehrsprachigkeit der Korpora sowie deren Lückenhaftigkeit, Begrenzung und mangelnde Metadatenauszeichnung Probleme dar. Wir stellen vor diesem Hintergrund einen sprach- und metadaten-agnostischen Workflow vor, der interaktive Exploration von kleineren, fest umrissenen historischen Korpora erlaubt. Texte können möglichst unabhängig von ihrer Sprache, der Menge ihrer Metadaten oder ihrer Länge analysiert und erkundet werden. Dazu nutzen wir ein multilinguales Sprachmodell: Einerseits führen wir ein multilinguales, topologisches Topic Modeling durch. Andererseits erstellen wir eine embedding-basierte interaktive Karte des Korpus, die mit den resultierenden Topics annotiert wird und mit deren Hilfe das Textkorpus navigiert und exploriert werden kann. Damit stellen wir einen Workflow vor, der es erlaubt, basierend auf digitalen Analysen Fragen an auch kleineren Textkorpora zu explorieren und über eine Visualisierung in die Close-Reading-Analyse überzugehen.</p><p>Mit unserer Einreichung stellen wir den aktuellen Arbeitsstand des Projekts »Computational Approaches to Narrative Space in 19th and 20th Century Novels« (CANSpiN) vor, das im Rahmen des DFG-Schwerpunktprogramms »Computational Literary Studies« (SPP 2207) von April 2023 bis März 2026 gefördert wird. Ziel des Vorhabens ist es, computergestützte Methoden zur Erkennung und Analyse narrativen Raums in literarischen Texten zu entwickeln und diese Methoden für die Untersuchung literaturhistorischer Fragen zum Verhältnis von Raum und nationaler Identität in deutsch- und spanischsprachigen Romanen des 19. und 20. Jahrhunderts zur Anwendung zu bringen. Dieser Zielsetzung entspricht die Zusammensetzung der Projektgruppe, die aus Wissenschaftler:innen der Germanistik, Romanistik, den Digital Humanities und der Mathematik besteht.</p><p>Epigraf ist eine Plattform zur Erfassung, Annotation, Vernetzung und Publikation von Textdaten, die im Kontext des interakademischen Editionsprojekts "Die Deutschen Inschriften" entwickelt wurde und nun schrittweise für andere Projekte geöffnet wird. Im Zentrum des Beitrags steht die Diskussion und Verortung des Datenmodell von Epigraf vor dem Hintergrund seiner Entwicklungsgeschichte und mit Blick auf eine langfristige institutionelle Einbindung der Plattform in die Forschungslandschaft. Die Modellierung ist gleichzeitig auf eine dokumentenorientierte, detaillierte sowie tiefgehende Aufbereitung des Quellenmaterials und auf eine datenorientierte Strukturierung für statistische Analysen ausgerichtet. Über Export-Pipelines werden offene Standards wie TEI und graphorientierte Modellierungen wie RDF unterstützt.</p><p>Der Beitrag beschreibt ein digitales Editionsvorhaben, das den medizinhistorisch relevanten Conciliator differentiarum philosophorum et praecipue medicorum des Petrus von Abano (ca. 1250 bis ca. 1315) zum Gegenstand hat. Das besondere Augenmerk des Beitrags liegt <span style="color: rgb(3, 252, 0);">dabei</span> auf der Erörterung des Einsatzes von Konzepten der "Continuous Integration, Continuous Delivery" (CI/CD) aus der modernen Softwareentwicklung und damit verbundenen Potentialen automatisierter Abläufe und Prozesse, insbesondere in den Bereichen Kollation, XML-Ids, Erweiterungen der Edition, Normalisierung und Standoff-Markup. Der Beitrag hebt Vorteile im Bereich der Übersichtlichkeit, Flexibilität, Zeitersparnis und Qualitätskontrolle hervor und schließt mit Überlegungen zu der Vorstellung von Zwischenergebnissen, der Komplexitätsreduktion, der Automatisierbarkeit von Einzelschritten und der Korrektur und Dokumentation von Fehlerquellen.</p> </html>