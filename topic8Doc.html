 <!DOCTYPE html>  
    <html lang="de">  
<head>  
    <meta charset="UTF-8">  
    <title>topic</title>  
</head>   <p>Der Workshop beschäftigt sich mit Strategien der Erschließung, Erhaltung und Dokumentation des frühen digitalen Kulturerbes. Mit dem Verfall historischer Hardware wird diese Herausforderung eminent: Zu den Ansätzen zählen daher die sogenannten Emulatoren, die die ursprünglichen historischen Computersysteme auf modernen Betriebssysstemen simulieren. Mit Hands-on-Ansatz konzipiert, ist es Ziel des Workshops, die Teilnehmenden an die Arbeit mit Emulatoren heranzuführen, um gemeinsame Grundlagen für die anschließende Diskussion des Potenzials von Retrocomputing für die Digital Humanities zu schaffen.</p><p>The workshop is planned as a tutorial opened to all participants with an interest in learning about Open Research Data practices within the Geovistory environment. The workshop is planned as a tutorial based on the community project "Academic Education and Careers" and is open to all participants with an interest in learning about Open Research Data practices within the Geovistory environment. The workshop has two objectives: 1) Introduce participants to the principles of FAIR and Open Research Data management, so that participants can understand the usefulness of following those standards, not only for the publication of data and its potential reuse but also for how it can help the researcher throughout the research cycle. 2) Give participants insight into a FAIR data production workflow applying different modules of the Geovistory environment (Geovistory Toolbox, Project Webpage, and SPARQL-endpoint) from data production, to publication, to analysis and reuse.</p><p>Die AG Digital Humanities Theorie bietet diesen halbtägigen Workshop an. Der Fokus liegt auf Formaten des Theoriebezugs in der DH-Lehre. Gegenstände des Workshops sind ein von der AG erstellter Reader "DH-Theorie" sowie eine Paneldiskussion mit Expert*innen, die DH-Studiengänge im deutschsprachigen Raum konzipiert haben bzw. koordinieren. Wir fragen, wie explizit der Theoriebezug in den Studiengängen ist, welche theoretischen Grundlagen häufig herangezogen werden, welches Verständnis von Theorie zugrunde gelegt wird (Reflexion, Praxis oder Textsammlung) und wie sich wissenschaftstheoretisch die einzelnen Disziplinen in oder gegenüber den Digital Humanities positionieren. Gemeinsam wollen wir eine These auf die Frage nach dem aktuellen Stand und der weiteren Entwicklung der Rolle von Theorie in DH-Studiengängen (quo vadis?) wagen.</p><p>Im ganztägigen Workshop erlangen die Teilnehmenden erforderliche Kenntnisse, um Tools und Workflows für die Volltexterschließung unter der Vielzahl von Angeboten auszuwählen. Dabei legen wir einen besonderen Fokus auf Open-Source-Produkte wie OCR-D und OCR4all. Nach einer Einführung in OCR-Technologien folgen praktische Teile, in denen die jeweiligen Tools für je ca. 1,5 Stunden demonstriert und ausprobiert werden. Ergänzt werden diese um kurze Inputvorträge zu praktischen Fragen wie der Erstellung eines geeigneten Workflows oder zu Hinweisen, was es zu beachten gilt bei Förderanträgen für OCR-Projekte.</p><p>Die objektorientierte historische Forschung profitiert von den Entwicklungen in den Digital Humanities. Die Verwendung digitaler 3D-Modelle hat sich etabliert und traditionellen Darstellungsformen in den Forschungskontexten, wie analogen Modellen und zweidimensionalen Abbildungen und Texten, nicht nur ergänzt, sondern einen neuen Forschungs- und Vermittlungsraum geöffnet. Seit den frühen 1980er Jahren sind quellenbasierte, hypothetische 3D-Rekonstruktionen daher zunehmend zu Forschungsinstrumenten und unverzichtbaren Darstellungsmitteln geworden. Die Arbeitsgruppe Digitale 3D-Rekonstruktion wurde gegründet, um die Herausforderungen der digitalen Rekonstruktion von Kulturerbe in den Digital Humanities zu systematisieren und zu rationalisieren. Das Panel möchte die Entwicklung und Methodik der digitalen 3D-Rekonstruktion aus verschiedenen Perspektiven beleuchten und die Fragen der Standardisierung, Dokumentation und Veröffentlichung diskutieren. Das Panel beschäftigt sich mit der Methodik, Computer Vision und KI, Open Science und digitalen Forschungsinfrastrukturen sowie Einsatzmöglichkeiten in der kunsthistorischen Forschung und der Vermittlung vom kulturellen Erbe. Die Diskussion soll einen umfassenden Einblick in die Potenziale, Herausforderungen und Perspektiven der digitalen 3D-Rekonstruktion bieten.</p><p>Deep Learning hat bereits neue Erkenntnisse in den digitalen Geisteswissenschaften ermöglicht. Vormoderne Sprachen und Sprachen des globalen Südens bringen allerdings Herausforderungen mit sich, die aktuell diesen analytischen Zugriff in diesem Bereich noch nicht erlauben. Das Projekt "The Flow" entwickelt Lösungen für solche historische Korpora in den Bereichen Handschriftenerkennung, Entitätsidentifikation, Event-Extraktion, Topic Modeling und Clustering. Die Entwicklung der Webanwendung nopaque zielt darauf ab, diese bestehenden Methoden bzw. Werkzeuge in einem übergreifenden Workflow zu verbinden. Der Workshop stellt den aktuellen Stand von nopaque bzw. den Workflow vor. Ziel ist es, bei der Etablierung eines allgemein anwendbaren Workflows für Deep Learning die Vielfalt der Quellen und geisteswissenschaftlichen Forschung zu berücksichtigen. Wir laden Teilnehmer:innen ein, Ideen und Erfahrungen einzubringen und Implementierungen für nicht standardisierte Layouts, Schriften und Sprachen zu diskutieren. Der Workshop trägt dazu bei, unser Projektziel zu erreichen: maschinelles Lernen in allen Bereichen der Geschichtswissenschaft zugänglicher zu machen.</p><p>In den letzten 2-3 Jahren haben die vielfältigen Weisen, mit denen Bedeutung mittels großer Sprachmodelle hergestellt, untersucht und kommuniziert werden, bisherige Annahmen darüber, wie Forschende in den DH hermeneutische Bedeutung mit KI-basierten Instrumenten untersuchen, in Frage gestellt. Ziel des Panels ist es, die Konstruktion sprachlicher Bedeutung von Menschen und von großen Sprachmodellen durch eine theoretisch informierte und begrifflich differenzierte Beschreibungssprache genauer erfassen zu können, um auf diese Weise die Fortschritte, die Probleme und auch das Scheitern genauer beschreiben zu können. Geleistet wird dies durch (1) eine genauere Rekonstruktion der Bedeutungskonstruktion in großen Sprachmodellen, (2) einen systematischen Theorieimport aus der Sprachphilosophie, (3) durch einen Untersuchung des Zusammenhangs von Bedeutung, Wissen und Modell sowie (4) durch einen Blick auf die Rolle, die bedeutungsanalytische Verfahren in den Digital Humanities spielen.</p><p>Dieser Workshop konzentriert sich auf die Erforschung der Anwendungsmöglichkeiten und Herausforderungen von KI-basierten Anwendungen wie GPT und Large Language Models (LLMs) im Kontext digitaler Editionen. GPT-4, mindestens bis Juli 2023 das führende Modell, bietet erhebliche Potenziale, z.B. für die Umwandlung von unstrukturiertem Text in strukturierte Daten und die Erkennung von benannten Entitäten. Dennoch liefert es bislang noch unbefriedigende Ergebnisse, weshalb sorgfältige Überwachung und Feedbacksysteme unerlässlich sind. Die Integration von LLMs in Arbeitsabläufe und Webentwicklungsprojekte ist vielversprechend, erfordert jedoch noch konzeptionelle und dann auch technische Vorstudien. In Anbetracht der rasanten KI- und LLM-Entwicklungen lädt der Workshop dazu ein, zu experimentieren und Strategien für den effektiven Einsatz dieser Modelle in digitalen Editionsprojekten zu diskutieren.</p><p>Der Workshop bietet einen praktischen Einstieg in den Bezug und die Analyse der Daten und freien digitalen Objekte der Deutschen Nationalbibliothek (DNB). Neben einem Überblick über das vielseitige Datenangebot der DNB ist das Ziel des Hands-on-Workshops, den Teilnehmer*innen eine niedrigschwellige praktische Einführung in automatisierte Abfragen über die verschiedenen offenen Bezugswege sowie geeignete Datenformate zu geben. Die Teilnehmer*innen des Workshops erhalten einen Einblick in das DNBLab als Service für Wissenschaft und Forschung sowie das Arbeiten mit dem Bestand und den Normdaten der DNB. Durch das gemeinsame Bearbeiten einer exemplarischen Fragestellung werden Grundlagen für die Entwicklung weiterer Forschungsideen geschaffen.</p> </html>