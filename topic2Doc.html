 <!DOCTYPE html>  
    <html lang="de">  
<head>  
    <meta charset="UTF-8">  
    <title>topic</title>  
</head>   <p>Grundlage der textorientierten Forschung in den DH ist die Verfügbarkeit von maschinenlesbarem Text. Diese Anforderung kann bei digitalen Texten einfacher erfüllt werden als bei historischen Texten, wo zunächst eine Transformation in eine digitale Repräsentation zu realisieren ist. Mit der Anwendung des maschinellen Lernens in der automatischen Texterkennung ist ein enormer Fortschritt vollzogen worden. Dies betrifft die Zeichenerkennung und deren Genauigkeit. Hierbei kommen Methoden zum Einsatz, die dem Paradigma Lernen aus Beispielen folgen. Die dazu nötigen Trainingsdaten werden als Ground Truth (GT) bezeichnet. Die Erstellung von GT erfolgt zu einem Großteil manuell. Das erfordert einen hohen zeitlichen und finanziellen Aufwand. Aus diesem Grund entwickelt, pflegt, vermittelt und diskutiert das Projekt OCR-D u.a. GT-Richtlinien. Diese Richtlinien werden in einer kollaborativen Datenkultur verpflichtenden Umgebung erstellt und sollen sicherstellen, dass der Aufwand der GT-Erstellung minimiert werden kann. Im Rahmen des Workshops soll am Beispiel der Forschungsdatennutzung des Deutschen Textarchivs diese Datenkultur gemeinsam gelebt werden.</p><p>Der Workshop beschäftigt sich mit Strategien der Erschließung, Erhaltung und Dokumentation des frühen digitalen Kulturerbes. Mit dem Verfall historischer Hardware wird diese Herausforderung eminent: Zu den Ansätzen zählen daher die sogenannten Emulatoren, die die ursprünglichen historischen Computersysteme auf modernen Betriebssysstemen simulieren. Mit Hands-on-Ansatz konzipiert, ist es Ziel des Workshops, die Teilnehmenden an die Arbeit mit Emulatoren heranzuführen, um gemeinsame Grundlagen für die anschließende Diskussion des Potenzials von Retrocomputing für die Digital Humanities zu schaffen.</p><p>Der Workshop zielt im Sinne der FAIR-Prinzipien und im Hinblick auf konkrete Standardisierungsbestrebungen auf die Vernetzung geistes- und kulturwissenschaftlicher Daten durch Erstellung sogenannter BEACON-Dateien auf Basis der Gemeinsamen Normdatei (GND). In dem Workshop werden zunächst zwei Beispiele vorgeführt, an denen das grundlegende Vorgehen erläutert wird. Der Schwerpunkt liegt allerdings auf der praktischen Anwendung und Hands-On-Erprobung des BEACON-Verfahrens. Abgerundet wird die Veranstaltung durch Ausblicke auf erweiterte Anwendungsbereiche des Formats.</p><p>Der Workshop bietet einen praktischen Einstieg in den Bezug und die Analyse der Daten und freien digitalen Objekte der Deutschen Nationalbibliothek (DNB). Neben einem Überblick über das vielseitige Datenangebot der DNB ist das Ziel des Hands-on-Workshops, den Teilnehmer*innen eine niedrigschwellige praktische Einführung in automatisierte Abfragen über die verschiedenen offenen Bezugswege sowie geeignete Datenformate zu geben. Die Teilnehmer*innen des Workshops erhalten einen Einblick in das DNBLab als Service für Wissenschaft und Forschung sowie das Arbeiten mit dem Bestand und den Normdaten der DNB. Durch das gemeinsame Bearbeiten einer exemplarischen Fragestellung werden Grundlagen für die Entwicklung weiterer Forschungsideen geschaffen.</p><p>The workshop is planned as a tutorial opened to all participants with an interest in learning about Open Research Data practices within the Geovistory environment. The workshop is planned as a tutorial based on the community project "Academic Education and Careers" and is open to all participants with an interest in learning about Open Research Data practices within the Geovistory environment. The workshop has two objectives: 1) Introduce participants to the principles of FAIR and Open Research Data management, so that participants can understand the usefulness of following those standards, not only for the publication of data and its potential reuse but also for how it can help the researcher throughout the research cycle. 2) Give participants insight into a FAIR data production workflow applying different modules of the Geovistory environment (Geovistory Toolbox, Project Webpage, and SPARQL-endpoint) from data production, to publication, to analysis and reuse.</p><p>The workshop invites scholars in the arts and humanities, irrespective of their background, to explore the innovative platform of OpenMethods metablog. The nominated papers for this platform are assessed based on seven criteria: Scope, Openness, Relevance, Clarity, Diversity, Language, and Assessment and Validation. During the workshop, these criteria will be thoroughly discussed, such as whether nominated contents should only be about non-peer-reviewed formats like blog posts or podcasts. The workshop aims to engage participants in conceptual discussions, evaluating nominations, and crafting introductions for the metablog. The ultimate goal is to foster sustainability through community involvement and encourage participants to spread the word and collaborate with the platform.</p><p>In den letzten 2-3 Jahren haben die vielfältigen Weisen, mit denen Bedeutung mittels großer Sprachmodelle hergestellt, untersucht und kommuniziert werden, bisherige Annahmen darüber, wie Forschende in den DH hermeneutische Bedeutung mit KI-basierten Instrumenten untersuchen, in Frage gestellt. Ziel des Panels ist es, die Konstruktion sprachlicher Bedeutung von Menschen und von großen Sprachmodellen durch eine theoretisch informierte und begrifflich differenzierte Beschreibungssprache genauer erfassen zu können, um auf diese Weise die Fortschritte, die Probleme und auch das Scheitern genauer beschreiben zu können. Geleistet wird dies durch (1) eine genauere Rekonstruktion der Bedeutungskonstruktion in großen Sprachmodellen, (2) einen systematischen Theorieimport aus der Sprachphilosophie, (3) durch einen Untersuchung des Zusammenhangs von Bedeutung, Wissen und Modell sowie (4) durch einen Blick auf die Rolle, die bedeutungsanalytische Verfahren in den Digital Humanities spielen.</p><p>Im ganztägigen Workshop erlangen die Teilnehmenden erforderliche Kenntnisse, um Tools und Workflows für die Volltexterschließung unter der Vielzahl von Angeboten auszuwählen. Dabei legen wir einen besonderen Fokus auf Open-Source-Produkte wie OCR-D und OCR4all. Nach einer Einführung in OCR-Technologien folgen praktische Teile, in denen die jeweiligen Tools für je ca. 1,5 Stunden demonstriert und ausprobiert werden. Ergänzt werden diese um kurze Inputvorträge zu praktischen Fragen wie der Erstellung eines geeigneten Workflows oder zu Hinweisen, was es zu beachten gilt bei Förderanträgen für OCR-Projekte.</p><p>Die AG Digital Humanities Theorie bietet diesen halbtägigen Workshop an. Der Fokus liegt auf Formaten des Theoriebezugs in der DH-Lehre. Gegenstände des Workshops sind ein von der AG erstellter Reader "DH-Theorie" sowie eine Paneldiskussion mit Expert*innen, die DH-Studiengänge im deutschsprachigen Raum konzipiert haben bzw. koordinieren. Wir fragen, wie explizit der Theoriebezug in den Studiengängen ist, welche theoretischen Grundlagen häufig herangezogen werden, welches Verständnis von Theorie zugrunde gelegt wird (Reflexion, Praxis oder Textsammlung) und wie sich wissenschaftstheoretisch die einzelnen Disziplinen in oder gegenüber den Digital Humanities positionieren. Gemeinsam wollen wir eine These auf die Frage nach dem aktuellen Stand und der weiteren Entwicklung der Rolle von Theorie in DH-Studiengängen (quo vadis?) wagen.</p> </html>