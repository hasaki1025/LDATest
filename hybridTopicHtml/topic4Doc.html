 <!DOCTYPE html>  
    <html lang="de">  
<head>  
    <meta charset="UTF-8">  
    <title>topic</title>  
</head>   <p>Die AG Digital Humanities Theorie bietet diesen halbtägigen Workshop an. Der Fokus liegt auf Formaten des Theoriebezugs in der DH-Lehre. Gegenstände des Workshops sind ein von der AG erstellter Reader "DH-Theorie" sowie eine Paneldiskussion mit Expert*innen, die DH-Studiengänge im deutschsprachigen Raum konzipiert haben bzw. koordinieren. Wir fragen, wie explizit der Theoriebezug in den Studiengängen ist, welche theoretischen Grundlagen häufig herangezogen werden, welches Verständnis von Theorie zugrunde gelegt wird (Reflexion, Praxis oder Textsammlung) und wie sich wissenschaftstheoretisch die einzelnen Disziplinen in oder gegenüber den Digital Humanities positionieren. Gemeinsam wollen wir eine These auf die Frage nach dem aktuellen Stand und der weiteren Entwicklung der Rolle von Theorie in DH-Studiengängen (quo vadis?) wagen.</p><p>Der Workshop bietet einen praktischen Einstieg in den Bezug und die Analyse der Daten und freien digitalen Objekte der Deutschen Nationalbibliothek (DNB). Neben einem Überblick über das vielseitige Datenangebot der DNB ist das Ziel des Hands-on-Workshops, den Teilnehmer*innen eine niedrigschwellige praktische Einführung in automatisierte Abfragen über die verschiedenen offenen Bezugswege sowie geeignete Datenformate zu geben. Die Teilnehmer*innen des Workshops erhalten einen Einblick in das DNBLab als Service für Wissenschaft und Forschung sowie das Arbeiten mit dem Bestand und den Normdaten der DNB. Durch das gemeinsame Bearbeiten einer exemplarischen Fragestellung werden Grundlagen für die Entwicklung weiterer Forschungsideen geschaffen.</p><p>The <span style="color: rgb(3, 252, 0);">workshop</span> is planned as a tutorial opened to all participants with an interest in learning about Open Research Data practices within the Geovistory environment. The <span style="color: rgb(3, 252, 0);">workshop</span> is planned as a tutorial based on the community project "Academic Education and Careers" and is <span style="color: rgb(4, 251, 0);">open</span> to all participants with an interest in learning about Open Research Data practices within the Geovistory environment. The <span style="color: rgb(3, 252, 0);">workshop</span> has two objectives: 1) Introduce participants to the principles of FAIR and Open Research Data management, so that participants can understand the usefulness of following those standards, not only for the publication of data and its potential reuse but also for how it can help the researcher throughout the <span style="color: rgb(3, 252, 0);">research</span> cycle. 2) Give participants insight into a FAIR data production workflow applying different modules of the Geovistory environment (Geovistory Toolbox, Project Webpage, and SPARQL-endpoint) from data production, to publication, to analysis and reuse.</p><p>Im ganztägigen Workshop erlangen die Teilnehmenden erforderliche Kenntnisse, um Tools und Workflows für die Volltexterschließung unter der Vielzahl von Angeboten auszuwählen. Dabei legen wir einen besonderen Fokus auf Open-Source-Produkte wie OCR-D und OCR4all. Nach einer Einführung in OCR-Technologien folgen praktische Teile, in denen die jeweiligen Tools für je ca. 1,5 Stunden demonstriert und ausprobiert werden. Ergänzt werden diese um kurze Inputvorträge zu praktischen Fragen wie der Erstellung eines geeigneten Workflows oder zu Hinweisen, was es zu beachten gilt bei Förderanträgen für OCR-Projekte.</p><p>In den letzten 2-3 Jahren haben die vielfältigen Weisen, mit denen Bedeutung mittels großer Sprachmodelle hergestellt, untersucht und kommuniziert werden, bisherige Annahmen darüber, wie Forschende in den DH hermeneutische Bedeutung mit KI-basierten Instrumenten untersuchen, in Frage gestellt. Ziel des Panels ist es, die Konstruktion sprachlicher Bedeutung von Menschen und von großen Sprachmodellen durch eine theoretisch informierte und begrifflich differenzierte Beschreibungssprache genauer erfassen zu können, um auf diese Weise die Fortschritte, die Probleme und auch das Scheitern genauer beschreiben zu können. Geleistet wird dies durch (1) eine genauere Rekonstruktion der Bedeutungskonstruktion in großen Sprachmodellen, (2) einen systematischen Theorieimport aus der Sprachphilosophie, (3) durch einen Untersuchung des Zusammenhangs von Bedeutung, Wissen und Modell sowie (4) durch einen Blick auf die Rolle, die bedeutungsanalytische Verfahren in den Digital Humanities spielen.</p><p>Forschungsdatenmanagement berührt inzwischen alle Bereiche in der Wissenschaft, da während jedes Forschungsprozesses – insbesondere auch in den Digital Humanities – (digitale) Daten jeder Art anfallen, die als Forschungsdaten bezeichnet werden. Mittelgeber geben vor, dass bei der Antragstellung bereits ein Datenmanagementplan (DMP) erstellt werden muss, um den Umgang mit den Daten während, aber auch nach, der Projektlaufzeit genau zu erfassen. Aspekte des Klimaschutzes werden hier noch nicht berücksichtigt, aber zeitgleich zur steigenden Anzahl an digitalen Daten und Methoden schreitet auch die Klimakrise voran. Dies berührt Aspekte der Digital Humanities, da hier neben steigenden Mengen digitaler Daten auch Methoden, technische Prozesse und Speicherroutinen zu berücksichtigen sind. Daher sollen in diesem Workshop gemeinsam Fragen zu einem und der Prozess eines grünen Forschungsdatenmanagements diskutiert sowie ein Musterdatenmanagementplan entwickelt werden.</p><p>Die kollaborativ erstellte Online-Enzyklopädie Wikipedia bietet mit derzeit über 60 Millionen Artikeln in über 300 Sprachversionen Informationen zu den unterschiedlichsten Wissensbereichen. Auch die rezeptionsorientierte Literaturwissenschaft hat das Projekt inzwischen als Forschungsgegenstand und Datenressource entdeckt, da es viele enzyklopädische Beiträge und Metadaten zur Literatur und zum literarischen Leben versammelt, zu Autor*innen, literarischen Werken, Genres, Epochen und anderen literaturgeschichtlich relevanten Kategorien. Die datenanalytische Auswertung verschiedener Wikipedia-Metriken ermöglicht es, die Auseinandersetzung mit Literatur in Wikipedia evaluierbar zu machen und Aussagen über literarische Kanonizität, Wertungspraktiken und Popularität im Kontext offener Enzyklopädieprojekte weiter zu diversifizieren. Im Zentrum des (hands-on) Workshops steht die Wikipedia-API, mit deren Funktionsweise die Teilnehmer*innen vertraut gemacht werden. Sukzessive werden Abfrageskripte in Form eines Jupyter Notebooks erarbeitet.</p><p>Der Workshop zielt im Sinne der FAIR-Prinzipien und im Hinblick auf konkrete Standardisierungsbestrebungen auf die Vernetzung geistes- und kulturwissenschaftlicher Daten durch Erstellung sogenannter BEACON-Dateien auf Basis der Gemeinsamen Normdatei (GND). In dem Workshop werden zunächst zwei Beispiele vorgeführt, an denen das grundlegende Vorgehen erläutert wird. Der Schwerpunkt liegt allerdings auf der praktischen Anwendung und Hands-On-Erprobung des BEACON-Verfahrens. Abgerundet wird die Veranstaltung durch Ausblicke auf erweiterte Anwendungsbereiche des Formats.</p><p>In diesem Workshop möchte die AG Datenzentren in Kooperation mit dem Institut für Inklusive Bildung der Christian-Albrechts-Universität zu Kiel bei Forschenden und Forschungsdatenmanager*innen ein Bewusstsein für Inklusion im Datenmanagement schaffen. Im Mittelpunkt des Workshops stehen das praktische Erproben und das gemeinsame Bewerten digitaler Zugänglichkeit und Barrierefreiheit am Beispiel des Kriteriums der Verständlichkeit. Konkret auftretende Hürden bei der Bereitstellung und Verwaltung sowie Nutzung von Datenrepositorien sollen im Workshop an einem ausgewählten Beispiel festgestellt und mögliche Lösungsansätze gemeinsam erarbeitet und diskutiert werden. Ein Erfahrungsbericht zum Datenmanagement aus einem partizipativen Forschungsprojekt der Universität Kiel gibt hierfür die nötigen Impulse.</p> </html>